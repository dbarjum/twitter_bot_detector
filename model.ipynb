{
 "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Cleaning User Data and Model\n",
     "\n",
     "In this section we clean data related to the user and then we create and train our Neural Network model.\n",
     "\n",
     "Import functions that will be necessary throughout this section."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
       "Using TensorFlow backend.\n"
      ]
     }
    ],
    "source": [
     "import pandas as pd\n",
     "import numpy as np\n",
     "import os\n",
     "from sklearn.model_selection import train_test_split\n",
     "\n",
     "from keras.models import Sequential, Model\n",
     "from keras.layers import Dropout, Flatten, Dense, Activation, Input, Reshape, InputLayer, Lambda, BatchNormalization\n",
     "from keras.utils import np_utils, to_categorical\n",
     "from keras.losses import binary_crossentropy\n",
     "from keras import backend as K,objectives\n",
     "from keras.losses import mse, binary_crossentropy\n",
     "\n",
     "# from keras.layers.advanced_activations import LeakyReLU\n",
     "from keras.callbacks import EarlyStopping\n",
     "from keras.optimizers import Adam, RMSprop\n",
     "from keras.initializers import RandomNormal\n",
     "import matplotlib.pyplot as plt\n",
     "import random\n",
     "\n",
     "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
     "from sklearn.metrics import confusion_matrix"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "We first read the data for users from the first file to create a dataframe:"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 2,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
     {
      "data": {
       "text/plain": [
        "(3474, 43)"
       ]
      },
      "execution_count": 2,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_users = pd.read_csv(\"data/datasets_full/genuine_accounts/users.csv\")\n",
     "df_users[\"bots\"] = 0\n",
     "df_users.head()\n",
     "df_users.shape"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "We create list of all the other files from which we want to read user's data and append them into the dataframe above. "
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 3,
    "metadata": {},
    "outputs": [],
    "source": [
     "user_files = [\"fake_followers\", \"social_spambots_1\", \"social_spambots_2\", \"social_spambots_3\", \n",
     "              \"traditional_spambots_1\", \"traditional_spambots_2\", \"traditional_spambots_3\", \"traditional_spambots_4\"]"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 4,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
       "/usr/share/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
       "of pandas will change to not sort by default.\n",
       "\n",
       "To accept the future behavior, pass 'sort=False'.\n",
       "\n",
       "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
       "\n",
       "  sort=sort)\n"
      ]
     }
    ],
    "source": [
     "for i in user_files:\n",
     "    df_temp = pd.read_csv(\"data/datasets_full/\" + i + \"/users.csv\")\n",
     "    df_temp[\"bots\"] = 1\n",
     "#     print (i, df_temp.shape)\n",
     "    df_users = df_users.append(df_temp, ignore_index=True)\n",
     "#     print (df_users.shape)\n",
     "# print (df_users.shape)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "We Excluded columns \"test_set_1\", \"test_set_2\", which are not useful to our work, and is not consistently present in all files"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 5,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "(14368, 41)"
       ]
      },
      "execution_count": 5,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_users = df_users.drop([\"test_set_1\", \"test_set_2\"], axis = 1)\n",
     "df_users.shape"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 6,
    "metadata": {
     "scrolled": false
    },
    "outputs": [
     {
      "data": {
       "text/html": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>bots</th>\n",
        "      <th>contributors_enabled</th>\n",
        "      <th>crawled_at</th>\n",
        "      <th>created_at</th>\n",
        "      <th>default_profile</th>\n",
        "      <th>default_profile_image</th>\n",
        "      <th>description</th>\n",
        "      <th>favourites_count</th>\n",
        "      <th>follow_request_sent</th>\n",
        "      <th>followers_count</th>\n",
        "      <th>...</th>\n",
        "      <th>profile_use_background_image</th>\n",
        "      <th>protected</th>\n",
        "      <th>screen_name</th>\n",
        "      <th>statuses_count</th>\n",
        "      <th>time_zone</th>\n",
        "      <th>timestamp</th>\n",
        "      <th>updated</th>\n",
        "      <th>url</th>\n",
        "      <th>utc_offset</th>\n",
        "      <th>verified</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2015-05-02 06:41:46</td>\n",
        "      <td>Tue Jun 11 11:20:35 +0000 2013</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>15years ago X.Lines24</td>\n",
        "      <td>265</td>\n",
        "      <td>NaN</td>\n",
        "      <td>208</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0918Bask</td>\n",
        "      <td>2177</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2013-06-11 13:20:35</td>\n",
        "      <td>2016-03-15 15:53:47</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2015-05-01 17:20:27</td>\n",
        "      <td>Tue May 13 10:37:57 +0000 2014</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>保守見習い地元大好き人間。 経済学、電工、仏教を勉強中、ちなDeではいかんのか？ (*^◯^*)</td>\n",
        "      <td>3972</td>\n",
        "      <td>NaN</td>\n",
        "      <td>330</td>\n",
        "      <td>...</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1120Roll</td>\n",
        "      <td>2660</td>\n",
        "      <td>Tokyo</td>\n",
        "      <td>2014-05-13 12:37:57</td>\n",
        "      <td>2016-03-15 15:53:48</td>\n",
        "      <td>NaN</td>\n",
        "      <td>32400.0</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2015-05-01 18:48:28</td>\n",
        "      <td>Wed May 04 23:30:37 +0000 2011</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Let me see what your best move is!</td>\n",
        "      <td>1185</td>\n",
        "      <td>NaN</td>\n",
        "      <td>166</td>\n",
        "      <td>...</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>14KBBrown</td>\n",
        "      <td>1254</td>\n",
        "      <td>Eastern Time (US &amp; Canada)</td>\n",
        "      <td>2011-05-05 01:30:37</td>\n",
        "      <td>2016-03-15 15:53:48</td>\n",
        "      <td>NaN</td>\n",
        "      <td>-14400.0</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2015-05-01 13:55:16</td>\n",
        "      <td>Fri Sep 17 14:02:10 +0000 2010</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>20. menna: #farida #nyc and the 80s actually y...</td>\n",
        "      <td>60304</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2248</td>\n",
        "      <td>...</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>wadespeters</td>\n",
        "      <td>202968</td>\n",
        "      <td>Greenland</td>\n",
        "      <td>2010-09-17 16:02:10</td>\n",
        "      <td>2016-03-15 15:53:48</td>\n",
        "      <td>http://t.co/rGV0HIJGsu</td>\n",
        "      <td>-7200.0</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2015-05-02 01:17:32</td>\n",
        "      <td>Fri Feb 06 04:10:49 +0000 2015</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Cosmetologist</td>\n",
        "      <td>5</td>\n",
        "      <td>NaN</td>\n",
        "      <td>21</td>\n",
        "      <td>...</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>191a5bd05da04dc</td>\n",
        "      <td>82</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2015-02-06 05:10:49</td>\n",
        "      <td>2016-03-15 15:53:48</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows × 41 columns</p>\n",
        "</div>"
       ],
       "text/plain": [
        "   bots  contributors_enabled           crawled_at  \\\n",
        "0     0                   NaN  2015-05-02 06:41:46   \n",
        "1     0                   NaN  2015-05-01 17:20:27   \n",
        "2     0                   NaN  2015-05-01 18:48:28   \n",
        "3     0                   NaN  2015-05-01 13:55:16   \n",
        "4     0                   NaN  2015-05-02 01:17:32   \n",
        "\n",
        "                       created_at  default_profile  default_profile_image  \\\n",
        "0  Tue Jun 11 11:20:35 +0000 2013              NaN                    NaN   \n",
        "1  Tue May 13 10:37:57 +0000 2014              1.0                    NaN   \n",
        "2  Wed May 04 23:30:37 +0000 2011              NaN                    NaN   \n",
        "3  Fri Sep 17 14:02:10 +0000 2010              NaN                    NaN   \n",
        "4  Fri Feb 06 04:10:49 +0000 2015              1.0                    NaN   \n",
        "\n",
        "                                         description  favourites_count  \\\n",
        "0                              15years ago X.Lines24               265   \n",
        "1   保守見習い地元大好き人間。 経済学、電工、仏教を勉強中、ちなDeではいかんのか？ (*^◯^*)              3972   \n",
        "2                 Let me see what your best move is!              1185   \n",
        "3  20. menna: #farida #nyc and the 80s actually y...             60304   \n",
        "4                                      Cosmetologist                 5   \n",
        "\n",
        "   follow_request_sent  followers_count    ...     \\\n",
        "0                  NaN              208    ...      \n",
        "1                  NaN              330    ...      \n",
        "2                  NaN              166    ...      \n",
        "3                  NaN             2248    ...      \n",
        "4                  NaN               21    ...      \n",
        "\n",
        "   profile_use_background_image  protected      screen_name  statuses_count  \\\n",
        "0                           NaN        NaN         0918Bask            2177   \n",
        "1                           1.0        NaN         1120Roll            2660   \n",
        "2                           1.0        NaN        14KBBrown            1254   \n",
        "3                           1.0        NaN      wadespeters          202968   \n",
        "4                           1.0        NaN  191a5bd05da04dc              82   \n",
        "\n",
        "                    time_zone            timestamp              updated  \\\n",
        "0                         NaN  2013-06-11 13:20:35  2016-03-15 15:53:47   \n",
        "1                       Tokyo  2014-05-13 12:37:57  2016-03-15 15:53:48   \n",
        "2  Eastern Time (US & Canada)  2011-05-05 01:30:37  2016-03-15 15:53:48   \n",
        "3                   Greenland  2010-09-17 16:02:10  2016-03-15 15:53:48   \n",
        "4                         NaN  2015-02-06 05:10:49  2016-03-15 15:53:48   \n",
        "\n",
        "                      url utc_offset  verified  \n",
        "0                     NaN        NaN       NaN  \n",
        "1                     NaN    32400.0       NaN  \n",
        "2                     NaN   -14400.0       NaN  \n",
        "3  http://t.co/rGV0HIJGsu    -7200.0       NaN  \n",
        "4                     NaN        NaN       NaN  \n",
        "\n",
        "[5 rows x 41 columns]"
       ]
      },
      "execution_count": 6,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_users.head()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 7,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
     {
      "data": {
       "text/html": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>bots</th>\n",
        "      <th>contributors_enabled</th>\n",
        "      <th>default_profile</th>\n",
        "      <th>default_profile_image</th>\n",
        "      <th>favourites_count</th>\n",
        "      <th>follow_request_sent</th>\n",
        "      <th>followers_count</th>\n",
        "      <th>following</th>\n",
        "      <th>friends_count</th>\n",
        "      <th>geo_enabled</th>\n",
        "      <th>id</th>\n",
        "      <th>is_translator</th>\n",
        "      <th>listed_count</th>\n",
        "      <th>notifications</th>\n",
        "      <th>profile_background_tile</th>\n",
        "      <th>profile_use_background_image</th>\n",
        "      <th>protected</th>\n",
        "      <th>statuses_count</th>\n",
        "      <th>utc_offset</th>\n",
        "      <th>verified</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>14368.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4511.0</td>\n",
        "      <td>78.0</td>\n",
        "      <td>14368.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.436800e+04</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14368.000000</td>\n",
        "      <td>3433.0</td>\n",
        "      <td>1.436800e+04</td>\n",
        "      <td>1.0</td>\n",
        "      <td>14368.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5501.0</td>\n",
        "      <td>12845.0</td>\n",
        "      <td>78.0</td>\n",
        "      <td>14368.000000</td>\n",
        "      <td>5350.000000</td>\n",
        "      <td>11.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>0.758213</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1145.288280</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8.682774e+02</td>\n",
        "      <td>NaN</td>\n",
        "      <td>589.318834</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.121055e+09</td>\n",
        "      <td>1.0</td>\n",
        "      <td>11.173998</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>5063.190910</td>\n",
        "      <td>-6071.046729</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>0.428181</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6036.894173</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2.688472e+04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2665.832959</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.901599e+08</td>\n",
        "      <td>NaN</td>\n",
        "      <td>266.966297</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17493.409898</td>\n",
        "      <td>18859.405855</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>1.0</td>\n",
        "      <td>6.780330e+05</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>-39600.000000</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>1.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>6.000000e+00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>42.000000</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.950380e+08</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>31.000000</td>\n",
        "      <td>-18000.000000</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>1.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2.500000e+01</td>\n",
        "      <td>NaN</td>\n",
        "      <td>250.000000</td>\n",
        "      <td>1.0</td>\n",
        "      <td>6.178160e+08</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>63.000000</td>\n",
        "      <td>-14400.000000</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>1.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>9.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>3.320000e+02</td>\n",
        "      <td>NaN</td>\n",
        "      <td>538.000000</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.354045e+09</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1365.250000</td>\n",
        "      <td>10800.000000</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>1.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>313954.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2.991573e+06</td>\n",
        "      <td>NaN</td>\n",
        "      <td>211890.000000</td>\n",
        "      <td>1.0</td>\n",
        "      <td>4.331280e+09</td>\n",
        "      <td>1.0</td>\n",
        "      <td>24348.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>399555.000000</td>\n",
        "      <td>46800.000000</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "text/plain": [
        "               bots  contributors_enabled  default_profile  \\\n",
        "count  14368.000000                   0.0           4511.0   \n",
        "mean       0.758213                   NaN              1.0   \n",
        "std        0.428181                   NaN              0.0   \n",
        "min        0.000000                   NaN              1.0   \n",
        "25%        1.000000                   NaN              1.0   \n",
        "50%        1.000000                   NaN              1.0   \n",
        "75%        1.000000                   NaN              1.0   \n",
        "max        1.000000                   NaN              1.0   \n",
        "\n",
        "       default_profile_image  favourites_count  follow_request_sent  \\\n",
        "count                   78.0      14368.000000                  0.0   \n",
        "mean                     1.0       1145.288280                  NaN   \n",
        "std                      0.0       6036.894173                  NaN   \n",
        "min                      1.0          0.000000                  NaN   \n",
        "25%                      1.0          0.000000                  NaN   \n",
        "50%                      1.0          0.000000                  NaN   \n",
        "75%                      1.0          9.000000                  NaN   \n",
        "max                      1.0     313954.000000                  NaN   \n",
        "\n",
        "       followers_count  following  friends_count  geo_enabled            id  \\\n",
        "count     1.436800e+04        0.0   14368.000000       3433.0  1.436800e+04   \n",
        "mean      8.682774e+02        NaN     589.318834          1.0  1.121055e+09   \n",
        "std       2.688472e+04        NaN    2665.832959          0.0  9.901599e+08   \n",
        "min       0.000000e+00        NaN       0.000000          1.0  6.780330e+05   \n",
        "25%       6.000000e+00        NaN      42.000000          1.0  1.950380e+08   \n",
        "50%       2.500000e+01        NaN     250.000000          1.0  6.178160e+08   \n",
        "75%       3.320000e+02        NaN     538.000000          1.0  2.354045e+09   \n",
        "max       2.991573e+06        NaN  211890.000000          1.0  4.331280e+09   \n",
        "\n",
        "       is_translator  listed_count  notifications  profile_background_tile  \\\n",
        "count            1.0  14368.000000            0.0                   5501.0   \n",
        "mean             1.0     11.173998            NaN                      1.0   \n",
        "std              NaN    266.966297            NaN                      0.0   \n",
        "min              1.0      0.000000            NaN                      1.0   \n",
        "25%              1.0      0.000000            NaN                      1.0   \n",
        "50%              1.0      0.000000            NaN                      1.0   \n",
        "75%              1.0      3.000000            NaN                      1.0   \n",
        "max              1.0  24348.000000            NaN                      1.0   \n",
        "\n",
        "       profile_use_background_image  protected  statuses_count    utc_offset  \\\n",
        "count                       12845.0       78.0    14368.000000   5350.000000   \n",
        "mean                            1.0        1.0     5063.190910  -6071.046729   \n",
        "std                             0.0        0.0    17493.409898  18859.405855   \n",
        "min                             1.0        1.0        0.000000 -39600.000000   \n",
        "25%                             1.0        1.0       31.000000 -18000.000000   \n",
        "50%                             1.0        1.0       63.000000 -14400.000000   \n",
        "75%                             1.0        1.0     1365.250000  10800.000000   \n",
        "max                             1.0        1.0   399555.000000  46800.000000   \n",
        "\n",
        "       verified  \n",
        "count      11.0  \n",
        "mean        1.0  \n",
        "std         0.0  \n",
        "min         1.0  \n",
        "25%         1.0  \n",
        "50%         1.0  \n",
        "75%         1.0  \n",
        "max         1.0  "
       ]
      },
      "execution_count": 7,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_users.describe()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 8,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
     {
      "data": {
       "text/plain": [
        "(14368, 41)"
       ]
      },
      "execution_count": 8,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_users.shape"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "We kept the variables that might have explanatory power, and/or have enough information that would be useful for our models. Many of the excluded variables did not have enough information to be useful (mostly NaNs). Others did not seem contribute at all for identifying fake tweets, for example the date in which the account was created (although we found useful the informatoin on the date in which the tweets are created, and we kept the latter). "
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 9,
    "metadata": {},
    "outputs": [],
    "source": [
     "users_features_to_keep = [\"favourites_count\", \"followers_count\", \"friends_count\", \"id\", \"listed_count\", \"statuses_count\", \"bots\"]"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 10,
    "metadata": {},
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
       "/usr/share/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame\n",
       "\n",
       "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
       "  return super(DataFrame, self).rename(**kwargs)\n"
      ]
     },
     {
      "data": {
       "text/html": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>favourites_count</th>\n",
        "      <th>followers_count</th>\n",
        "      <th>friends_count</th>\n",
        "      <th>user_id</th>\n",
        "      <th>listed_count</th>\n",
        "      <th>statuses_count</th>\n",
        "      <th>bots</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>14368.000000</td>\n",
        "      <td>1.436800e+04</td>\n",
        "      <td>14368.000000</td>\n",
        "      <td>1.436800e+04</td>\n",
        "      <td>14368.000000</td>\n",
        "      <td>14368.000000</td>\n",
        "      <td>14368.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>1145.288280</td>\n",
        "      <td>8.682774e+02</td>\n",
        "      <td>589.318834</td>\n",
        "      <td>1.121055e+09</td>\n",
        "      <td>11.173998</td>\n",
        "      <td>5063.190910</td>\n",
        "      <td>0.758213</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>6036.894173</td>\n",
        "      <td>2.688472e+04</td>\n",
        "      <td>2665.832959</td>\n",
        "      <td>9.901599e+08</td>\n",
        "      <td>266.966297</td>\n",
        "      <td>17493.409898</td>\n",
        "      <td>0.428181</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>6.780330e+05</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>6.000000e+00</td>\n",
        "      <td>42.000000</td>\n",
        "      <td>1.950380e+08</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>31.000000</td>\n",
        "      <td>1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>2.500000e+01</td>\n",
        "      <td>250.000000</td>\n",
        "      <td>6.178160e+08</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>63.000000</td>\n",
        "      <td>1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>9.000000</td>\n",
        "      <td>3.320000e+02</td>\n",
        "      <td>538.000000</td>\n",
        "      <td>2.354045e+09</td>\n",
        "      <td>3.000000</td>\n",
        "      <td>1365.250000</td>\n",
        "      <td>1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>313954.000000</td>\n",
        "      <td>2.991573e+06</td>\n",
        "      <td>211890.000000</td>\n",
        "      <td>4.331280e+09</td>\n",
        "      <td>24348.000000</td>\n",
        "      <td>399555.000000</td>\n",
        "      <td>1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "text/plain": [
        "       favourites_count  followers_count  friends_count       user_id  \\\n",
        "count      14368.000000     1.436800e+04   14368.000000  1.436800e+04   \n",
        "mean        1145.288280     8.682774e+02     589.318834  1.121055e+09   \n",
        "std         6036.894173     2.688472e+04    2665.832959  9.901599e+08   \n",
        "min            0.000000     0.000000e+00       0.000000  6.780330e+05   \n",
        "25%            0.000000     6.000000e+00      42.000000  1.950380e+08   \n",
        "50%            0.000000     2.500000e+01     250.000000  6.178160e+08   \n",
        "75%            9.000000     3.320000e+02     538.000000  2.354045e+09   \n",
        "max       313954.000000     2.991573e+06  211890.000000  4.331280e+09   \n",
        "\n",
        "       listed_count  statuses_count          bots  \n",
        "count  14368.000000    14368.000000  14368.000000  \n",
        "mean      11.173998     5063.190910      0.758213  \n",
        "std      266.966297    17493.409898      0.428181  \n",
        "min        0.000000        0.000000      0.000000  \n",
        "25%        0.000000       31.000000      1.000000  \n",
        "50%        0.000000       63.000000      1.000000  \n",
        "75%        3.000000     1365.250000      1.000000  \n",
        "max    24348.000000   399555.000000      1.000000  "
       ]
      },
      "execution_count": 10,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_users_clean = df_users[users_features_to_keep]\n",
     "df_users_clean.rename(columns={'id': 'user_id'}, inplace=True)\n",
     "df_users_clean.describe()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 11,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "(14368, 7)"
       ]
      },
      "execution_count": 11,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_users_clean.shape"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 12,
    "metadata": {},
    "outputs": [],
    "source": [
     "df_users_clean.to_csv(\"data/clean_users.csv\", index=False)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Modeling"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "For modeling, we take two approaches, we created a baseline model and then improve upon it. Both models are neural nets and produce a probability between 0 and 1 about whether a user is a bot (1) or not (0). Our networks estimate the probability that a given tweet comes from a bot or from a genuine account, we then average the probabilities of the tweets for a given user in order to estimate the probability that the user is a bot or not. In other words, this is a two step process:\n",
     "1. Neural network predicts if a given tweet is from bot or not.\n",
     "2. Average of predictions for each user is generated to predict whether a user is bot or not.\n",
     "\n",
     "We do this as it is difficult to abstract from a single tweet (observation) if an account is genuine or from bot."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "We begin by reading in the cleaned datasets that we did and merge them together."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 13,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
       "/usr/share/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
       "  mask |= (ar1 == a)\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "CPU times: user 31.7 s, sys: 4.26 s, total: 35.9 s\n",
       "Wall time: 34 s\n"
      ]
     }
    ],
    "source": [
     "%%time \n",
     "df_tweets = pd.read_csv(\"data/clean_tweets.csv\", index_col=0)\n",
     "df_users = pd.read_csv(\"data/clean_users.csv\")\n",
     "df_NN = df_tweets.merge(df_users, on=\"user_id\", how=\"left\").fillna(\"\")"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 14,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "(6492521, 30)\n",
       "(14368, 7)\n",
       "(6492521, 36)\n"
      ]
     }
    ],
    "source": [
     "print(df_tweets.shape)\n",
     "print(df_users.shape)\n",
     "print(df_NN.shape)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 15,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
     {
      "data": {
       "text/plain": [
        "0.0"
       ]
      },
      "execution_count": 15,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "sum(abs(df_NN.bots_x - df_NN.bots_y))"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 16,
    "metadata": {},
    "outputs": [],
    "source": [
     "df_NN[\"bots\"] = df_NN.bots_x\n",
     "# df_NN.columns\n",
     "df_NN = df_NN.drop(columns = [\"bots_x\", \"bots_y\"])\n",
     "# df_NN.columns"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 17,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/html": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>favorite_count</th>\n",
        "      <th>num_hashtags</th>\n",
        "      <th>num_mentions</th>\n",
        "      <th>num_urls</th>\n",
        "      <th>reply_count</th>\n",
        "      <th>retweet_count</th>\n",
        "      <th>user_id</th>\n",
        "      <th>reply</th>\n",
        "      <th>location_data</th>\n",
        "      <th>num_words</th>\n",
        "      <th>...</th>\n",
        "      <th>day</th>\n",
        "      <th>hour</th>\n",
        "      <th>minute</th>\n",
        "      <th>second</th>\n",
        "      <th>favourites_count</th>\n",
        "      <th>followers_count</th>\n",
        "      <th>friends_count</th>\n",
        "      <th>listed_count</th>\n",
        "      <th>statuses_count</th>\n",
        "      <th>bots</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>...</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "      <td>6.492521e+06</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>2.405442e+00</td>\n",
        "      <td>1.565306e-01</td>\n",
        "      <td>3.924238e-01</td>\n",
        "      <td>1.897788e-01</td>\n",
        "      <td>2.912012e-02</td>\n",
        "      <td>3.918497e+02</td>\n",
        "      <td>7.325286e+08</td>\n",
        "      <td>1.583126e-01</td>\n",
        "      <td>1.981526e-02</td>\n",
        "      <td>1.255200e+01</td>\n",
        "      <td>...</td>\n",
        "      <td>1.655101e+01</td>\n",
        "      <td>1.230295e+01</td>\n",
        "      <td>2.936419e+01</td>\n",
        "      <td>2.941542e+01</td>\n",
        "      <td>2.500700e+03</td>\n",
        "      <td>2.328122e+03</td>\n",
        "      <td>1.338941e+03</td>\n",
        "      <td>2.174600e+01</td>\n",
        "      <td>1.405835e+04</td>\n",
        "      <td>5.626720e-01</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>3.350790e+02</td>\n",
        "      <td>5.931723e-01</td>\n",
        "      <td>7.243254e-01</td>\n",
        "      <td>3.978721e-01</td>\n",
        "      <td>1.490583e+01</td>\n",
        "      <td>1.112564e+04</td>\n",
        "      <td>7.495175e+08</td>\n",
        "      <td>3.650339e-01</td>\n",
        "      <td>1.393651e-01</td>\n",
        "      <td>6.678471e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>9.296943e+00</td>\n",
        "      <td>7.035330e+00</td>\n",
        "      <td>1.737085e+01</td>\n",
        "      <td>1.736926e+01</td>\n",
        "      <td>7.913393e+03</td>\n",
        "      <td>2.472806e+04</td>\n",
        "      <td>3.179826e+03</td>\n",
        "      <td>1.504893e+02</td>\n",
        "      <td>2.699921e+04</td>\n",
        "      <td>4.960567e-01</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>-1.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>6.780330e+05</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>2.158760e+08</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>7.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>8.000000e+00</td>\n",
        "      <td>6.000000e+00</td>\n",
        "      <td>1.400000e+01</td>\n",
        "      <td>1.400000e+01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.770000e+02</td>\n",
        "      <td>1.980000e+02</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>4.900000e+02</td>\n",
        "      <td>0.000000e+00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>4.836202e+08</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.200000e+01</td>\n",
        "      <td>...</td>\n",
        "      <td>1.700000e+01</td>\n",
        "      <td>1.300000e+01</td>\n",
        "      <td>2.900000e+01</td>\n",
        "      <td>2.900000e+01</td>\n",
        "      <td>2.000000e+00</td>\n",
        "      <td>6.080000e+02</td>\n",
        "      <td>6.040000e+02</td>\n",
        "      <td>3.000000e+00</td>\n",
        "      <td>7.411000e+03</td>\n",
        "      <td>1.000000e+00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>6.162066e+08</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.800000e+01</td>\n",
        "      <td>...</td>\n",
        "      <td>2.500000e+01</td>\n",
        "      <td>1.800000e+01</td>\n",
        "      <td>4.400000e+01</td>\n",
        "      <td>4.400000e+01</td>\n",
        "      <td>1.632000e+03</td>\n",
        "      <td>1.234000e+03</td>\n",
        "      <td>1.652000e+03</td>\n",
        "      <td>9.000000e+00</td>\n",
        "      <td>1.263900e+04</td>\n",
        "      <td>1.000000e+00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>1.353000e+05</td>\n",
        "      <td>2.800000e+01</td>\n",
        "      <td>1.900000e+01</td>\n",
        "      <td>6.000000e+00</td>\n",
        "      <td>2.751600e+04</td>\n",
        "      <td>3.350111e+06</td>\n",
        "      <td>2.525273e+09</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>6.900000e+01</td>\n",
        "      <td>...</td>\n",
        "      <td>3.100000e+01</td>\n",
        "      <td>2.300000e+01</td>\n",
        "      <td>5.900000e+01</td>\n",
        "      <td>5.900000e+01</td>\n",
        "      <td>1.854670e+05</td>\n",
        "      <td>9.868370e+05</td>\n",
        "      <td>9.086100e+04</td>\n",
        "      <td>4.840000e+03</td>\n",
        "      <td>3.335040e+05</td>\n",
        "      <td>1.000000e+00</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows × 32 columns</p>\n",
        "</div>"
       ],
       "text/plain": [
        "       favorite_count  num_hashtags  num_mentions      num_urls   reply_count  \\\n",
        "count    6.492521e+06  6.492521e+06  6.492521e+06  6.492521e+06  6.492521e+06   \n",
        "mean     2.405442e+00  1.565306e-01  3.924238e-01  1.897788e-01  2.912012e-02   \n",
        "std      3.350790e+02  5.931723e-01  7.243254e-01  3.978721e-01  1.490583e+01   \n",
        "min     -1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "50%      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "75%      0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
        "max      1.353000e+05  2.800000e+01  1.900000e+01  6.000000e+00  2.751600e+04   \n",
        "\n",
        "       retweet_count       user_id         reply  location_data     num_words  \\\n",
        "count   6.492521e+06  6.492521e+06  6.492521e+06   6.492521e+06  6.492521e+06   \n",
        "mean    3.918497e+02  7.325286e+08  1.583126e-01   1.981526e-02  1.255200e+01   \n",
        "std     1.112564e+04  7.495175e+08  3.650339e-01   1.393651e-01  6.678471e+00   \n",
        "min     0.000000e+00  6.780330e+05  0.000000e+00   0.000000e+00  0.000000e+00   \n",
        "25%     0.000000e+00  2.158760e+08  0.000000e+00   0.000000e+00  7.000000e+00   \n",
        "50%     0.000000e+00  4.836202e+08  0.000000e+00   0.000000e+00  1.200000e+01   \n",
        "75%     0.000000e+00  6.162066e+08  0.000000e+00   0.000000e+00  1.800000e+01   \n",
        "max     3.350111e+06  2.525273e+09  1.000000e+00   1.000000e+00  6.900000e+01   \n",
        "\n",
        "           ...                day          hour        minute        second  \\\n",
        "count      ...       6.492521e+06  6.492521e+06  6.492521e+06  6.492521e+06   \n",
        "mean       ...       1.655101e+01  1.230295e+01  2.936419e+01  2.941542e+01   \n",
        "std        ...       9.296943e+00  7.035330e+00  1.737085e+01  1.736926e+01   \n",
        "min        ...       1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%        ...       8.000000e+00  6.000000e+00  1.400000e+01  1.400000e+01   \n",
        "50%        ...       1.700000e+01  1.300000e+01  2.900000e+01  2.900000e+01   \n",
        "75%        ...       2.500000e+01  1.800000e+01  4.400000e+01  4.400000e+01   \n",
        "max        ...       3.100000e+01  2.300000e+01  5.900000e+01  5.900000e+01   \n",
        "\n",
        "       favourites_count  followers_count  friends_count  listed_count  \\\n",
        "count      6.492521e+06     6.492521e+06   6.492521e+06  6.492521e+06   \n",
        "mean       2.500700e+03     2.328122e+03   1.338941e+03  2.174600e+01   \n",
        "std        7.913393e+03     2.472806e+04   3.179826e+03  1.504893e+02   \n",
        "min        0.000000e+00     0.000000e+00   0.000000e+00  0.000000e+00   \n",
        "25%        0.000000e+00     1.770000e+02   1.980000e+02  0.000000e+00   \n",
        "50%        2.000000e+00     6.080000e+02   6.040000e+02  3.000000e+00   \n",
        "75%        1.632000e+03     1.234000e+03   1.652000e+03  9.000000e+00   \n",
        "max        1.854670e+05     9.868370e+05   9.086100e+04  4.840000e+03   \n",
        "\n",
        "       statuses_count          bots  \n",
        "count    6.492521e+06  6.492521e+06  \n",
        "mean     1.405835e+04  5.626720e-01  \n",
        "std      2.699921e+04  4.960567e-01  \n",
        "min      0.000000e+00  0.000000e+00  \n",
        "25%      4.900000e+02  0.000000e+00  \n",
        "50%      7.411000e+03  1.000000e+00  \n",
        "75%      1.263900e+04  1.000000e+00  \n",
        "max      3.335040e+05  1.000000e+00  \n",
        "\n",
        "[8 rows x 32 columns]"
       ]
      },
      "execution_count": 17,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_NN.describe()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 18,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "created_at                    0\n",
        "favorite_count                0\n",
        "num_hashtags                  0\n",
        "num_mentions                  0\n",
        "num_urls                      0\n",
        "reply_count                   0\n",
        "retweet_count                 0\n",
        "text                          0\n",
        "timestamp                     0\n",
        "user_id                       0\n",
        "reply                         0\n",
        "location_data                 0\n",
        "num_words                     0\n",
        "source_Facebook               0\n",
        "source_Instagram              0\n",
        "source_TweetAdder v4          0\n",
        "source_TweetDeck              0\n",
        "source_Twitter Web Client     0\n",
        "source_Twitter for Android    0\n",
        "source_Twitter for Mac        0\n",
        "source_Twitter for iPad       0\n",
        "source_Twitter for iPhone     0\n",
        "source_other                  0\n",
        "year                          0\n",
        "month                         0\n",
        "day                           0\n",
        "hour                          0\n",
        "minute                        0\n",
        "second                        0\n",
        "favourites_count              0\n",
        "followers_count               0\n",
        "friends_count                 0\n",
        "listed_count                  0\n",
        "statuses_count                0\n",
        "bots                          0\n",
        "dtype: int64"
       ]
      },
      "execution_count": 18,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "df_NN.isna().sum()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Once we merged the datasets and have a single datasets with no missing information, we prepare the data for analysis. An important step is to split the test and train data based on users as the labeling form the researchers came as such. In other words, the label for bot or not bot is at the user level and not at the tweet level. As such, we make sure to separate train and test at user level first. \n",
     "\n",
     "Another way to put it, we randomly select 20% of users and create a test set of the tweets and features pertaining to these users. Information from these users will not be contained in the training set."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 19,
    "metadata": {},
    "outputs": [],
    "source": [
     "unique_users = df_NN.user_id.unique()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 20,
    "metadata": {},
    "outputs": [],
    "source": [
     "np.random.seed(42)\n",
     "user_id_test = np.random.choice(unique_users, size = int(0.2*len(unique_users)))"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 21,
    "metadata": {},
    "outputs": [],
    "source": [
     "# save test users to csv in order to compare results with botometer\n",
     "# np.savetxt('data/user_id_test.csv', user_id_test, delimiter=\",\")"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 22,
    "metadata": {
     "scrolled": true
    },
    "outputs": [],
    "source": [
     "test_df_by_usr = df_NN[df_NN.user_id.isin(user_id_test)]"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 23,
    "metadata": {},
    "outputs": [],
    "source": [
     "train_df_by_user = df_NN[df_NN.user_id.isin(set(user_id_test)^set(unique_users))]"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 24,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Take a sample of the data, so that training does not take too long when debugging.\n",
     "# df_NN = df_NN.sample(n=10**6, random_state = 42)\n",
     "# df_NN.shape"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Separate X data (data of features to be used for prediction) and Y data (class)."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 25,
    "metadata": {},
    "outputs": [],
    "source": [
     "y_df_NN = train_df_by_user.bots\n",
     "X_df_NN = train_df_by_user.drop(columns = [\"created_at\", \"text\", \"timestamp\", \"user_id\",\n",
     "                                           \"bots\", \"year\", \"month\", \"day\", \"hour\", \"minute\"], axis = 1)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Train and test split, and check that it worked"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 26,
    "metadata": {},
    "outputs": [],
    "source": [
     "# splitting the dataset into train and test\n",
     "X_train, X_test, y_train, y_test = train_test_split(X_df_NN, y_df_NN, test_size=0.3, random_state=42, stratify = y_df_NN)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 27,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "0.7"
       ]
      },
      "execution_count": 27,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "# testing split\n",
     "X_train.shape[0]/(X_train.shape[0] + X_test.shape[0])\n",
     "# y_train.shape"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 28,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "1.0    2107330\n",
        "0.0    1601494\n",
        "Name: bots, dtype: int64"
       ]
      },
      "execution_count": 28,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "y_train.value_counts()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 29,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "0.4318064162656411\n",
       "0.4318060567626468\n"
      ]
     }
    ],
    "source": [
     "# testing that stratify worked as wanted\n",
     "print (y_train.value_counts()[0]/(y_train.value_counts()[1]+y_train.value_counts()[0]))\n",
     "print (y_test.value_counts()[0]/(y_test.value_counts()[1]+y_test.value_counts()[0]))"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 30,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "['favorite_count',\n",
        " 'num_hashtags',\n",
        " 'num_mentions',\n",
        " 'num_urls',\n",
        " 'reply_count',\n",
        " 'retweet_count',\n",
        " 'reply',\n",
        " 'location_data',\n",
        " 'num_words',\n",
        " 'source_Facebook',\n",
        " 'source_Instagram',\n",
        " 'source_TweetAdder v4',\n",
        " 'source_TweetDeck',\n",
        " 'source_Twitter Web Client',\n",
        " 'source_Twitter for Android',\n",
        " 'source_Twitter for Mac',\n",
        " 'source_Twitter for iPad',\n",
        " 'source_Twitter for iPhone',\n",
        " 'source_other',\n",
        " 'second',\n",
        " 'favourites_count',\n",
        " 'followers_count',\n",
        " 'friends_count',\n",
        " 'listed_count',\n",
        " 'statuses_count']"
       ]
      },
      "execution_count": 30,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "list(X_train.columns)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 31,
    "metadata": {},
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
       "/usr/share/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
       "  return self.partial_fit(X, y)\n"
      ]
     }
    ],
    "source": [
     "# Preprocessing the data: first step will be to create a normalized dataframe  \n",
     "\n",
     "scaler = MinMaxScaler()\n",
     "\n",
     "transformer = scaler.fit(X_train)\n",
     "X_train_scaled = pd.DataFrame(transformer.transform(X_train))\n",
     "\n",
     "X_test_scaled = pd.DataFrame(transformer.transform(X_test))"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Check to see that normalization of features worked."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 32,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/html": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>15</th>\n",
        "      <th>16</th>\n",
        "      <th>17</th>\n",
        "      <th>18</th>\n",
        "      <th>19</th>\n",
        "      <th>20</th>\n",
        "      <th>21</th>\n",
        "      <th>22</th>\n",
        "      <th>23</th>\n",
        "      <th>24</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>...</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "      <td>3.708824e+06</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>2.420196e-05</td>\n",
        "      <td>5.485162e-03</td>\n",
        "      <td>2.045787e-02</td>\n",
        "      <td>3.187228e-02</td>\n",
        "      <td>1.423564e-06</td>\n",
        "      <td>1.172674e-04</td>\n",
        "      <td>1.579781e-01</td>\n",
        "      <td>1.979846e-02</td>\n",
        "      <td>1.821568e-01</td>\n",
        "      <td>1.342717e-02</td>\n",
        "      <td>...</td>\n",
        "      <td>4.377938e-03</td>\n",
        "      <td>1.520806e-02</td>\n",
        "      <td>1.807476e-01</td>\n",
        "      <td>3.244430e-01</td>\n",
        "      <td>4.984980e-01</td>\n",
        "      <td>1.297191e-02</td>\n",
        "      <td>2.461070e-03</td>\n",
        "      <td>3.394426e-02</td>\n",
        "      <td>4.460104e-03</td>\n",
        "      <td>4.039490e-02</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>2.129653e-03</td>\n",
        "      <td>2.061854e-02</td>\n",
        "      <td>3.788882e-02</td>\n",
        "      <td>6.638563e-02</td>\n",
        "      <td>6.523086e-04</td>\n",
        "      <td>3.267120e-03</td>\n",
        "      <td>3.647205e-01</td>\n",
        "      <td>1.393072e-01</td>\n",
        "      <td>9.657781e-02</td>\n",
        "      <td>1.150951e-01</td>\n",
        "      <td>...</td>\n",
        "      <td>6.602100e-02</td>\n",
        "      <td>1.223796e-01</td>\n",
        "      <td>3.848090e-01</td>\n",
        "      <td>4.681664e-01</td>\n",
        "      <td>2.943571e-01</td>\n",
        "      <td>4.280644e-02</td>\n",
        "      <td>2.769149e-02</td>\n",
        "      <td>5.840290e-02</td>\n",
        "      <td>3.204073e-02</td>\n",
        "      <td>7.682065e-02</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>7.390928e-06</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.014493e-01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>2.372881e-01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.783476e-04</td>\n",
        "      <td>5.212672e-03</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.490237e-03</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>7.390928e-06</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.739130e-01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>4.915254e-01</td>\n",
        "      <td>5.391795e-06</td>\n",
        "      <td>6.161099e-04</td>\n",
        "      <td>1.622914e-02</td>\n",
        "      <td>6.198347e-04</td>\n",
        "      <td>2.222162e-02</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>7.390928e-06</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>5.263158e-02</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>2.608696e-01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>7.457627e-01</td>\n",
        "      <td>8.400416e-03</td>\n",
        "      <td>1.247420e-03</td>\n",
        "      <td>4.438832e-02</td>\n",
        "      <td>1.652893e-03</td>\n",
        "      <td>3.753478e-02</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows × 25 columns</p>\n",
        "</div>"
       ],
       "text/plain": [
        "                 0             1             2             3             4   \\\n",
        "count  3.708824e+06  3.708824e+06  3.708824e+06  3.708824e+06  3.708824e+06   \n",
        "mean   2.420196e-05  5.485162e-03  2.045787e-02  3.187228e-02  1.423564e-06   \n",
        "std    2.129653e-03  2.061854e-02  3.788882e-02  6.638563e-02  6.523086e-04   \n",
        "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%    7.390928e-06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "50%    7.390928e-06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "75%    7.390928e-06  0.000000e+00  5.263158e-02  0.000000e+00  0.000000e+00   \n",
        "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
        "\n",
        "                 5             6             7             8             9   \\\n",
        "count  3.708824e+06  3.708824e+06  3.708824e+06  3.708824e+06  3.708824e+06   \n",
        "mean   1.172674e-04  1.579781e-01  1.979846e-02  1.821568e-01  1.342717e-02   \n",
        "std    3.267120e-03  3.647205e-01  1.393072e-01  9.657781e-02  1.150951e-01   \n",
        "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%    0.000000e+00  0.000000e+00  0.000000e+00  1.014493e-01  0.000000e+00   \n",
        "50%    0.000000e+00  0.000000e+00  0.000000e+00  1.739130e-01  0.000000e+00   \n",
        "75%    0.000000e+00  0.000000e+00  0.000000e+00  2.608696e-01  0.000000e+00   \n",
        "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
        "\n",
        "           ...                 15            16            17            18  \\\n",
        "count      ...       3.708824e+06  3.708824e+06  3.708824e+06  3.708824e+06   \n",
        "mean       ...       4.377938e-03  1.520806e-02  1.807476e-01  3.244430e-01   \n",
        "std        ...       6.602100e-02  1.223796e-01  3.848090e-01  4.681664e-01   \n",
        "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "75%        ...       0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00   \n",
        "max        ...       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
        "\n",
        "                 19            20            21            22            23  \\\n",
        "count  3.708824e+06  3.708824e+06  3.708824e+06  3.708824e+06  3.708824e+06   \n",
        "mean   4.984980e-01  1.297191e-02  2.461070e-03  3.394426e-02  4.460104e-03   \n",
        "std    2.943571e-01  4.280644e-02  2.769149e-02  5.840290e-02  3.204073e-02   \n",
        "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%    2.372881e-01  0.000000e+00  1.783476e-04  5.212672e-03  0.000000e+00   \n",
        "50%    4.915254e-01  5.391795e-06  6.161099e-04  1.622914e-02  6.198347e-04   \n",
        "75%    7.457627e-01  8.400416e-03  1.247420e-03  4.438832e-02  1.652893e-03   \n",
        "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
        "\n",
        "                 24  \n",
        "count  3.708824e+06  \n",
        "mean   4.039490e-02  \n",
        "std    7.682065e-02  \n",
        "min    0.000000e+00  \n",
        "25%    1.490237e-03  \n",
        "50%    2.222162e-02  \n",
        "75%    3.753478e-02  \n",
        "max    1.000000e+00  \n",
        "\n",
        "[8 rows x 25 columns]"
       ]
      },
      "execution_count": 32,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "X_train_scaled.describe()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 33,
    "metadata": {
     "scrolled": false
    },
    "outputs": [
     {
      "data": {
       "text/html": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>15</th>\n",
        "      <th>16</th>\n",
        "      <th>17</th>\n",
        "      <th>18</th>\n",
        "      <th>19</th>\n",
        "      <th>20</th>\n",
        "      <th>21</th>\n",
        "      <th>22</th>\n",
        "      <th>23</th>\n",
        "      <th>24</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>...</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "      <td>1.589496e+06</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>3.008399e-05</td>\n",
        "      <td>5.463861e-03</td>\n",
        "      <td>2.052965e-02</td>\n",
        "      <td>3.187037e-02</td>\n",
        "      <td>1.977188e-06</td>\n",
        "      <td>1.166702e-04</td>\n",
        "      <td>1.578047e-01</td>\n",
        "      <td>1.983585e-02</td>\n",
        "      <td>1.822536e-01</td>\n",
        "      <td>1.339859e-02</td>\n",
        "      <td>...</td>\n",
        "      <td>4.390071e-03</td>\n",
        "      <td>1.525767e-02</td>\n",
        "      <td>1.809819e-01</td>\n",
        "      <td>3.243846e-01</td>\n",
        "      <td>4.979953e-01</td>\n",
        "      <td>1.302839e-02</td>\n",
        "      <td>2.425514e-03</td>\n",
        "      <td>3.400537e-02</td>\n",
        "      <td>4.432355e-03</td>\n",
        "      <td>4.032176e-02</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>3.152337e-03</td>\n",
        "      <td>2.055627e-02</td>\n",
        "      <td>3.789402e-02</td>\n",
        "      <td>6.640853e-02</td>\n",
        "      <td>1.143136e-03</td>\n",
        "      <td>3.263673e-03</td>\n",
        "      <td>3.645579e-01</td>\n",
        "      <td>1.394360e-01</td>\n",
        "      <td>9.656662e-02</td>\n",
        "      <td>1.149742e-01</td>\n",
        "      <td>...</td>\n",
        "      <td>6.611203e-02</td>\n",
        "      <td>1.225760e-01</td>\n",
        "      <td>3.850033e-01</td>\n",
        "      <td>4.681446e-01</td>\n",
        "      <td>2.944804e-01</td>\n",
        "      <td>4.330879e-02</td>\n",
        "      <td>2.713501e-02</td>\n",
        "      <td>5.826074e-02</td>\n",
        "      <td>3.165589e-02</td>\n",
        "      <td>7.662602e-02</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>7.390928e-06</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>7.390928e-06</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.014493e-01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>2.372881e-01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.793609e-04</td>\n",
        "      <td>5.239541e-03</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.490237e-03</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>7.390928e-06</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.739130e-01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>4.915254e-01</td>\n",
        "      <td>5.391795e-06</td>\n",
        "      <td>6.171232e-04</td>\n",
        "      <td>1.625601e-02</td>\n",
        "      <td>6.198347e-04</td>\n",
        "      <td>2.221862e-02</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>7.390928e-06</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>5.263158e-02</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>2.608696e-01</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>7.457627e-01</td>\n",
        "      <td>8.400416e-03</td>\n",
        "      <td>1.247420e-03</td>\n",
        "      <td>4.441519e-02</td>\n",
        "      <td>1.652893e-03</td>\n",
        "      <td>3.753478e-02</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>9.999926e-01</td>\n",
        "      <td>8.214286e-01</td>\n",
        "      <td>6.842105e-01</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.405168e+00</td>\n",
        "      <td>9.999997e-01</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>7.681159e-01</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>...</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "      <td>1.000000e+00</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows × 25 columns</p>\n",
        "</div>"
       ],
       "text/plain": [
        "                 0             1             2             3             4   \\\n",
        "count  1.589496e+06  1.589496e+06  1.589496e+06  1.589496e+06  1.589496e+06   \n",
        "mean   3.008399e-05  5.463861e-03  2.052965e-02  3.187037e-02  1.977188e-06   \n",
        "std    3.152337e-03  2.055627e-02  3.789402e-02  6.640853e-02  1.143136e-03   \n",
        "min    7.390928e-06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%    7.390928e-06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "50%    7.390928e-06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "75%    7.390928e-06  0.000000e+00  5.263158e-02  0.000000e+00  0.000000e+00   \n",
        "max    9.999926e-01  8.214286e-01  6.842105e-01  1.000000e+00  1.405168e+00   \n",
        "\n",
        "                 5             6             7             8             9   \\\n",
        "count  1.589496e+06  1.589496e+06  1.589496e+06  1.589496e+06  1.589496e+06   \n",
        "mean   1.166702e-04  1.578047e-01  1.983585e-02  1.822536e-01  1.339859e-02   \n",
        "std    3.263673e-03  3.645579e-01  1.394360e-01  9.656662e-02  1.149742e-01   \n",
        "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%    0.000000e+00  0.000000e+00  0.000000e+00  1.014493e-01  0.000000e+00   \n",
        "50%    0.000000e+00  0.000000e+00  0.000000e+00  1.739130e-01  0.000000e+00   \n",
        "75%    0.000000e+00  0.000000e+00  0.000000e+00  2.608696e-01  0.000000e+00   \n",
        "max    9.999997e-01  1.000000e+00  1.000000e+00  7.681159e-01  1.000000e+00   \n",
        "\n",
        "           ...                 15            16            17            18  \\\n",
        "count      ...       1.589496e+06  1.589496e+06  1.589496e+06  1.589496e+06   \n",
        "mean       ...       4.390071e-03  1.525767e-02  1.809819e-01  3.243846e-01   \n",
        "std        ...       6.611203e-02  1.225760e-01  3.850033e-01  4.681446e-01   \n",
        "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "75%        ...       0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00   \n",
        "max        ...       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
        "\n",
        "                 19            20            21            22            23  \\\n",
        "count  1.589496e+06  1.589496e+06  1.589496e+06  1.589496e+06  1.589496e+06   \n",
        "mean   4.979953e-01  1.302839e-02  2.425514e-03  3.400537e-02  4.432355e-03   \n",
        "std    2.944804e-01  4.330879e-02  2.713501e-02  5.826074e-02  3.165589e-02   \n",
        "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
        "25%    2.372881e-01  0.000000e+00  1.793609e-04  5.239541e-03  0.000000e+00   \n",
        "50%    4.915254e-01  5.391795e-06  6.171232e-04  1.625601e-02  6.198347e-04   \n",
        "75%    7.457627e-01  8.400416e-03  1.247420e-03  4.441519e-02  1.652893e-03   \n",
        "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
        "\n",
        "                 24  \n",
        "count  1.589496e+06  \n",
        "mean   4.032176e-02  \n",
        "std    7.662602e-02  \n",
        "min    0.000000e+00  \n",
        "25%    1.490237e-03  \n",
        "50%    2.221862e-02  \n",
        "75%    3.753478e-02  \n",
        "max    1.000000e+00  \n",
        "\n",
        "[8 rows x 25 columns]"
       ]
      },
      "execution_count": 33,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "X_test_scaled.describe()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Build, train, predict and check accuracy of baseline model, upon which we will build and improve in our final model"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 34,
    "metadata": {},
    "outputs": [],
    "source": [
     "# build the baseline model\n",
     "input_dim = X_train_scaled.shape[1]\n",
     "\n",
     "num_classes = 1\n",
     "nodes = 100\n",
     "\n",
     "baseline_model = Sequential()\n",
     "\n",
     "baseline_model.add(Dense(nodes, activation='relu', kernel_initializer='uniform', \n",
     "                input_dim = input_dim))\n",
     "\n",
     "baseline_model.add(Dense(nodes, activation='relu'))\n",
     "baseline_model.add(Dense(nodes, activation='relu'))\n",
     "baseline_model.add(Dense(nodes, activation='relu'))\n",
     "baseline_model.add(Dense(nodes, activation='relu'))\n",
     "baseline_model.add(Dense(nodes, activation='relu'))\n",
     "baseline_model.add(Dense(nodes, activation='relu'))\n",
     "\n",
     "baseline_model.add(Dense(num_classes, kernel_initializer='uniform', activation='sigmoid'))\n",
     "\n",
     "# compile the model\n",
     "baseline_model.compile(loss='binary_crossentropy',\n",
     "              optimizer='adam',\n",
     "              metrics=['acc'])"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Create functions to save model weights for later use."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 59,
    "metadata": {},
    "outputs": [],
    "source": [
     "def load_weights(folder):\n",
     "    final_model.load_weights(folder + '/final_model.w')\n",
     "    \n",
     "def save_weights(folder):\n",
     "    if not os.path.isdir(folder):\n",
     "        os.mkdir(folder)\n",
     "    final_model.save_weights(folder + '/final_model.w')"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Train Model if untrained."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 56,
    "metadata": {},
    "outputs": [],
    "source": [
     "training_flag = False"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 35,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Epoch 1/10\n",
       "3708824/3708824 [==============================] - 31s 8us/step - loss: 0.1026 - acc: 0.9618\n",
       "Epoch 2/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0543 - acc: 0.9796\n",
       "Epoch 3/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0321 - acc: 0.9884\n",
       "Epoch 4/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0223 - acc: 0.9922\n",
       "Epoch 5/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0175 - acc: 0.9941\n",
       "Epoch 6/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0145 - acc: 0.9951\n",
       "Epoch 7/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0126 - acc: 0.9959\n",
       "Epoch 8/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0106 - acc: 0.9964\n",
       "Epoch 9/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0095 - acc: 0.9968\n",
       "Epoch 10/10\n",
       "3708824/3708824 [==============================] - 26s 7us/step - loss: 0.0086 - acc: 0.9972\n",
       "CPU times: user 5min 12s, sys: 43.3 s, total: 5min 55s\n",
       "Wall time: 4min 25s\n"
      ]
     }
    ],
    "source": [
     "# Fit the baseline model\n",
     "batch_size = 2**10\n",
     "epochs = 10\n",
     "\n",
     "baseline_model_history = baseline_model.fit(X_train_scaled, y_train,\n",
     "                    batch_size=batch_size,\n",
     "                    epochs=epochs,\n",
     "                    verbose=1,\n",
     "                    shuffle=True)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 36,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "image/png": "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\n",
       "text/plain": [
        "<Figure size 648x432 with 1 Axes>"
       ]
      },
      "metadata": {
       "needs_background": "light"
      },
      "output_type": "display_data"
     }
    ],
    "source": [
     "fig, ax = plt.subplots(figsize=(9, 6))\n",
     "ax.plot(np.array(baseline_model_history.history['acc']), color='blue', label='training accuracy')\n",
     "ax.plot(np.array(baseline_model_history.history['loss']), color='red', label='training loss')\n",
     "# ax.set_title('optimizer={}, lr={}'.format('Adam', lr))\n",
     "ax.legend(loc='upper right')\n",
     "plt.show()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "We see that our base model learns as it progresses through the epochs. We have good scores for training accuracy in each epoch, but let's test overall performance"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 37,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Train confusion matrix:\n",
       " [[1532805   68689]\n",
       " [1171047  936283]]\n",
       "Train loss: 5.384253384901117\n",
       "Train accuracy: 0.6657333968934628\n"
      ]
     }
    ],
    "source": [
     "# evaluate the training and testing performance of our model \n",
     "score = baseline_model.evaluate(X_train, y_train, verbose=0)\n",
     "# get the class probabilities predicted by our MLP on the training set\n",
     "y_pred = baseline_model.predict(X_train)\n",
     "y_pred[y_pred > 0.5] = 1\n",
     "y_pred[y_pred <= 0.5] = 0\n",
     "print('Train confusion matrix:\\n', confusion_matrix(y_train, y_pred))\n",
     "print('Train loss:', score[0])\n",
     "print('Train accuracy:', score[1])"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 38,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Test confusion matrix:\n",
       " [[656897  29457]\n",
       " [501002 402140]]\n",
       "Test loss: 5.375560504454298\n",
       "Test accuracy: 0.6662722020064705\n"
      ]
     }
    ],
    "source": [
     "# evaluate the training and testing performance of our model \n",
     "score = baseline_model.evaluate(X_test, y_test, verbose=0)\n",
     "# get the class probabilities predicted by our MLP on the training set\n",
     "y_pred = baseline_model.predict(X_test)\n",
     "y_pred[y_pred > 0.5] = 1\n",
     "y_pred[y_pred <= 0.5] = 0\n",
     "print('Test confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
     "print('Test loss:', score[0])\n",
     "print('Test accuracy:', score[1])"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Build, train, predict and check accuracy of improved model"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 39,
    "metadata": {},
    "outputs": [],
    "source": [
     "# build the final model\n",
     "input_dim = X_train_scaled.shape[1]\n",
     "\n",
     "num_classes = 1\n",
     "nodes = 100\n",
     "\n",
     "final_model = Sequential()\n",
     "\n",
     "final_model.add(Dense(nodes, activation='relu', kernel_initializer='uniform', \n",
     "                input_dim = input_dim))\n",
     "\n",
     "final_model.add(Dense(nodes, activation='relu'))\n",
     "final_model.add(Dense(nodes, activation='relu'))\n",
     "\n",
     "final_model.add(Dropout(0.2))\n",
     "\n",
     "final_model.add(Dense(nodes, activation='relu'))\n",
     "final_model.add(Dense(nodes, activation='relu'))\n",
     "\n",
     "final_model.add(Dropout(0.2))\n",
     "\n",
     "final_model.add(Dense(nodes, activation='relu'))\n",
     "final_model.add(Dense(nodes, activation='relu'))\n",
     "\n",
     "final_model.add(Dense(num_classes, kernel_initializer='uniform', activation='sigmoid'))\n",
     "\n",
     "# compile the model\n",
     "final_model.compile(loss='binary_crossentropy',\n",
     "              optimizer='adam',\n",
     "              metrics=['acc'])"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 40,
    "metadata": {},
    "outputs": [],
    "source": [
     "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=5, mode='auto')"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 41,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Train on 3337941 samples, validate on 370883 samples\n",
       "Epoch 1/10\n",
       "3337941/3337941 [==============================] - 26s 8us/step - loss: 0.1042 - acc: 0.9616 - val_loss: 0.0788 - val_acc: 0.9700\n",
       "Epoch 2/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0561 - acc: 0.9786 - val_loss: 0.0404 - val_acc: 0.9842\n",
       "Epoch 3/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0407 - acc: 0.9847 - val_loss: 0.0301 - val_acc: 0.9892\n",
       "Epoch 4/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0323 - acc: 0.9882 - val_loss: 0.0265 - val_acc: 0.9906\n",
       "Epoch 5/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0270 - acc: 0.9903 - val_loss: 0.0208 - val_acc: 0.9931\n",
       "Epoch 6/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0228 - acc: 0.9920 - val_loss: 0.0167 - val_acc: 0.9944\n",
       "Epoch 7/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0200 - acc: 0.9931 - val_loss: 0.0171 - val_acc: 0.9934\n",
       "Epoch 8/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0178 - acc: 0.9939 - val_loss: 0.0107 - val_acc: 0.9963\n",
       "Epoch 9/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0164 - acc: 0.9945 - val_loss: 0.0113 - val_acc: 0.9961\n",
       "Epoch 10/10\n",
       "3337941/3337941 [==============================] - 25s 8us/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0157 - val_acc: 0.9953\n",
       "CPU times: user 4min 56s, sys: 44.4 s, total: 5min 41s\n",
       "Wall time: 4min 14s\n"
      ]
     }
    ],
    "source": [
     "%%time\n",
     "if training_flag:\n",
     "    \n",
     "# Fit the model\n",
     "    batch_size = 2**10\n",
     "    epochs = 10\n",
     "\n",
     "    final_model_history = final_model.fit(X_train_scaled, y_train,\n",
     "                    batch_size=batch_size,\n",
     "                    epochs=epochs,\n",
     "                    verbose=1,\n",
     "                    callbacks=[early_stopping],\n",
     "                    validation_split=0.1,\n",
     "                    shuffle=True,)\n",
     "    \n",
     "    \n",
     "    save_weights(folder='data/celeba_vae')\n",
     "else:\n",
     "    load_weights(folder='data/celeba_vae')"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 42,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "image/png": "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\n",
       "text/plain": [
        "<Figure size 648x432 with 1 Axes>"
       ]
      },
      "metadata": {
       "needs_background": "light"
      },
      "output_type": "display_data"
     }
    ],
    "source": [
     "fig, ax = plt.subplots(figsize=(9, 6))\n",
     "ax.plot(np.array(final_model_history.history['acc']), color='blue', label='training accuracy')\n",
     "ax.plot(np.array(final_model_history.history['loss']), color='red', label='training loss')\n",
     "ax.plot(np.array(final_model_history.history['val_acc']), color='black', label='validation training accuracy')\n",
     "ax.plot(np.array(final_model_history.history['val_loss']), color='yellow', label='validation training loss')\n",
     "# ax.set_title('optimizer={}, lr={}'.format('Adam', lr))\n",
     "ax.legend(loc='upper right')\n",
     "plt.show()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Check accuracy of train set"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 43,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Train confusion matrix:\n",
       " [[1541450   60044]\n",
       " [1181066  926264]]\n",
       "Train loss: 5.390812724318497\n",
       "Train accuracy: 0.6653629290579647\n"
      ]
     }
    ],
    "source": [
     "# evaluate the training and testing performance of our model \n",
     "score = final_model.evaluate(X_train, y_train, verbose=0)\n",
     "# get the class probabilities predicted by our MLP on the training set\n",
     "y_pred = final_model.predict(X_train)\n",
     "y_pred[y_pred > 0.5] = 1\n",
     "y_pred[y_pred <= 0.5] = 0\n",
     "print('Train confusion matrix:\\n', confusion_matrix(y_train, y_pred))\n",
     "print('Train loss:', score[0])\n",
     "print('Train accuracy:', score[1])"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Check accuracy of test set"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 44,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Test confusion matrix:\n",
       " [[660611  25743]\n",
       " [505178 397964]]\n",
       "Test loss: 5.380858372078886\n",
       "Test accuracy: 0.6659815438355786\n"
      ]
     }
    ],
    "source": [
     "# evaluate the training and testing performance of our model \n",
     "score = final_model.evaluate(X_test, y_test, verbose=0)\n",
     "# get the class probabilities predicted by our MLP on the training set\n",
     "y_pred = final_model.predict(X_test)\n",
     "y_pred[y_pred > 0.5] = 1\n",
     "y_pred[y_pred <= 0.5] = 0\n",
     "print('Test confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
     "print('Test loss:', score[0])\n",
     "print('Test accuracy:', score[1])"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 50,
    "metadata": {},
    "outputs": [],
    "source": [
     "final_y_test = test_df_by_usr.bots"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 49,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "final_x_test = test_df_by_usr.drop(columns = [\"created_at\", \"text\", \"timestamp\", \"user_id\",\n",
     "                                           \"bots\", \"year\", \"month\", \"day\", \"hour\", \"minute\"], axis = 1)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 51,
    "metadata": {},
    "outputs": [],
    "source": [
     "final_x_test_scaled = pd.DataFrame(transformer.transform(final_x_test))"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 52,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Test confusion matrix:\n",
       " [[519948  31565]\n",
       " [ 37191 605497]]\n",
       "Test loss: 0.4697286067304131\n",
       "Test accuracy: 0.9424251026418501\n"
      ]
     }
    ],
    "source": [
     "# evaluate the training and testing performance of our model \n",
     "score = baseline_model.evaluate(final_x_test_scaled, final_y_test, verbose=0)\n",
     "# get the class probabilities predicted by our MLP on the training set\n",
     "y_pred = baseline_model.predict(final_x_test_scaled)\n",
     "y_pred[y_pred > 0.5] = 1\n",
     "y_pred[y_pred <= 0.5] = 0\n",
     "print('Test confusion matrix:\\n', confusion_matrix(final_y_test, y_pred))\n",
     "print('Test loss:', score[0])\n",
     "print('Test accuracy:', score[1])"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 53,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Test confusion matrix:\n",
       " [[524894  26619]\n",
       " [ 35636 607052]]\n",
       "Test loss: 0.3894988631429476\n",
       "Test accuracy: 0.9478689098401358\n"
      ]
     }
    ],
    "source": [
     "# evaluate the training and testing performance of our model \n",
     "score = final_model.evaluate(final_x_test_scaled, final_y_test, verbose=0)\n",
     "# get the class probabilities predicted by our MLP on the training set\n",
     "y_pred = final_model.predict(final_x_test_scaled)\n",
     "y_pred[y_pred > 0.5] = 1\n",
     "y_pred[y_pred <= 0.5] = 0\n",
     "print('Test confusion matrix:\\n', confusion_matrix(final_y_test, y_pred))\n",
     "print('Test loss:', score[0])\n",
     "print('Test accuracy:', score[1])"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 62,
    "metadata": {},
    "outputs": [],
    "source": [
     "y_pred = final_model.predict(final_x_test_scaled)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 63,
    "metadata": {},
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
       "/usr/share/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
       "  \"\"\"Entry point for launching an IPython kernel.\n"
      ]
     }
    ],
    "source": [
     "test_df_by_usr['y_pred'] = y_pred"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 74,
    "metadata": {},
    "outputs": [],
    "source": [
     "y_pred = test_df_by_usr.groupby('user_id').y_pred.mean()\n"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 82,
    "metadata": {},
    "outputs": [],
    "source": [
     "botometer_df = pd.DataFrame({'user_id':y_pred.index, 'y_pred':y_pred.values})"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Saving the users in test set will be comparing against Botometer result"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 83,
    "metadata": {},
    "outputs": [],
    "source": [
     "botometer_df.to_csv('data/botometer_df.csv')"
    ]
   }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
